{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome!\n",
    "Below, we will learn to implement and train a policy to play atari-pong, using only the pixels as input. We will use convolutional neural nets, multiprocessing, and pytorch to implement and train our policy. Let's get started!\n",
    "\n",
    "(I strongly recommend you to try this notebook on the Udacity workspace first before running it locally on your desktop/laptop, as performance might suffer in different environments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of available actions:  ['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']\n"
     ]
    }
   ],
   "source": [
    "# render ai gym environment\n",
    "import gym\n",
    "import time\n",
    "\n",
    "# PongDeterministic does not contain random frameskip\n",
    "# so is faster to train than the vanilla Pong-v4 environment\n",
    "env = gym.make('PongDeterministic-v4')\n",
    "\n",
    "print(\"List of available actions: \", env.unwrapped.get_action_meanings())\n",
    "\n",
    "# we will only use the actions 'RIGHTFIRE' = 4 and 'LEFTFIRE\" = 5\n",
    "# the 'FIRE' part ensures that the game starts again after losing a life\n",
    "# the actions are hard-coded in pong_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "# custom utilies for displaying animation, collecting rollouts and more\n",
    "import pong_utils\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# check which device is being used. \n",
    "# I recommend disabling gpu until you've made sure that the code runs\n",
    "device = pong_utils.device\n",
    "print(\"using device: \",device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "To speed up training, we can simplify the input by cropping the images and use every other pixel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# show what a preprocessed image looks like\n",
    "env.reset()\n",
    "_, _, _, _ = env.step(0)\n",
    "# get a frame after 20 steps\n",
    "for _ in range(20):\n",
    "    frame, _, _, _ = env.step(1)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(frame)\n",
    "plt.title('original image')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('preprocessed image')\n",
    "\n",
    "# 80 x 80 black and white image\n",
    "plt.imshow(pong_utils.preprocess_single(frame), cmap='Greys')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy\n",
    "\n",
    "## Exercise 1: Implement your policy\n",
    " \n",
    "Here, we define our policy. The input is the stack of two different frames (which captures the movement), and the output is a number $P_{\\rm right}$, the probability of moving left. Note that $P_{\\rm left}= 1-P_{\\rm right}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# set up a convolutional neural net\n",
    "# the output is the probability of moving right\n",
    "# P(left) = 1-P(right)\n",
    "class Policy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Policy, self).__init__()\n",
    "        \n",
    "        # 80x80 to outputsize x outputsize\n",
    "        # outputsize = (inputsize - kernel_size + stride)/stride \n",
    "        # (round up if not an integer)\n",
    "\n",
    "        # conv1 : 80 x 80 -> 37 x 37\n",
    "        self.conv1 = nn.Conv2d(2, 4, kernel_size=8, stride=2)\n",
    "        # conv2 : 40 x 40 -> 17 x 17\n",
    "        self.conv2 = nn.Conv2d(4, 8, kernel_size=4, stride=2)\n",
    "        # conv3 : 20 x 20 -> 8 x 8\n",
    "        self.conv3 = nn.Conv2d(8, 16, kernel_size=2, stride=2)\n",
    "        # conv4 : 10 x 10 ->  7 x  7\n",
    "        self.conv4 = nn.Conv2d(16, 32, kernel_size=2)\n",
    "        self.size = 32 * 7 * 7\n",
    "        \n",
    "        # 1 fully connected layer\n",
    "        self.fc1 = nn.Linear(self.size, 64)\n",
    "        self.fc2 = nn.Linear(64, 8)\n",
    "        self.fc3 = nn.Linear(8, 1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        #print(x.shape)\n",
    "\n",
    "        x = x.view(-1, self.size)\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.fc1(x))  \n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.fc2(x))  \n",
    "        #print(x.shape)\n",
    "        x = self.sig(self.fc3(x))\n",
    "        #print(x.shape)\n",
    "        return x\n",
    "\n",
    "# use your own policy!\n",
    "policy=Policy().to(device)\n",
    "#policy=pong_utils.Policy().to(device)\n",
    "\n",
    "# we use the adam optimizer with learning rate 2e-4\n",
    "# optim.SGD is also possible\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(policy.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game visualization\n",
    "pong_utils contain a play function given the environment and a policy. An optional preprocess function can be supplied. Here we define a function that plays a game and shows learning progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-d67c274181b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpong_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpong_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpong_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess_single\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# try to add the option \"preprocess=pong_utils.preprocess_single\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# to see what the agent sees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\reinforcment learning\\deep-reinforcement-learning\\Udacity-DeepRL-PPO-master\\pong_utils.py\u001b[0m in \u001b[0;36mplay\u001b[1;34m(env, policy, time, preprocess, nrand)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m     \u001b[0manimate_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manim_frames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\reinforcment learning\\deep-reinforcement-learning\\Udacity-DeepRL-PPO-master\\pong_utils.py\u001b[0m in \u001b[0;36manimate_frames\u001b[1;34m(frames)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;31m#print((dtype))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdisplay_animation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfanim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'once'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;31m# play a game and display the animation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\drl\\lib\\site-packages\\JSAnimation\\IPython_display.py\u001b[0m in \u001b[0;36mdisplay_animation\u001b[1;34m(anim, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;34m\"\"\"Display the animation with an IPython HTML object\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHTML\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mHTML\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manim_to_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\drl\\lib\\site-packages\\JSAnimation\\IPython_display.py\u001b[0m in \u001b[0;36manim_to_html\u001b[1;34m(anim, fps, embed_frames, default_mode)\u001b[0m\n\u001b[0;32m     74\u001b[0m             anim.save(f.name,  writer=HTMLWriter(fps=fps,\n\u001b[0;32m     75\u001b[0m                                                  \u001b[0membed_frames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0membed_frames\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m                                                  default_mode=default_mode))\n\u001b[0m\u001b[0;32m     77\u001b[0m             \u001b[0mhtml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\drl\\lib\\site-packages\\matplotlib\\animation.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filename, writer, fps, dpi, codec, bitrate, extra_args, metadata, extra_anim, savefig_kwargs, progress_callback)\u001b[0m\n\u001b[0;32m   1154\u001b[0m                             \u001b[0mprogress_callback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe_number\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_frames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1155\u001b[0m                             \u001b[0mframe_number\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1156\u001b[1;33m                     \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrab_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0msavefig_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1158\u001b[0m         \u001b[1;31m# Reconnect signal for first draw if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\drl\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\drl\\lib\\site-packages\\matplotlib\\animation.py\u001b[0m in \u001b[0;36msaving\u001b[1;34m(self, fig, outfile, dpi, *args, **kwargs)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\drl\\lib\\site-packages\\matplotlib\\animation.py\u001b[0m in \u001b[0;36mfinish\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    526\u001b[0m         \u001b[1;31m# are available to be assembled.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m         \u001b[0mMovieWriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Will call clean-up\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\drl\\lib\\site-packages\\matplotlib\\animation.py\u001b[0m in \u001b[0;36mfinish\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfinish\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[1;34m'''Finish any processing for writing the movie.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgrab_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msavefig_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\drl\\lib\\site-packages\\matplotlib\\animation.py\u001b[0m in \u001b[0;36mcleanup\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m         \u001b[0mMovieWriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[1;31m# Delete temporary files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\drl\\lib\\site-packages\\matplotlib\\animation.py\u001b[0m in \u001b[0;36mcleanup\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    397\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_frame_sink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;31m# Use the encoding/errors that universal_newlines would use.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextIOWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m         \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextIOWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "import pong_utils\n",
    "\n",
    "pong_utils.play(env, policy, time=100, preprocess=pong_utils.preprocess_single) \n",
    "# try to add the option \"preprocess=pong_utils.preprocess_single\"\n",
    "# to see what the agent sees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rollout\n",
    "Before we start the training, we need to collect samples. To make things efficient we use parallelized environments to collect multiple examples at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'probs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-b6239b35ae79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0menvs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpong_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallelEnv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'PongDeterministic-v4'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12345\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpong_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect_trajectories\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menvs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'probs' is not defined"
     ]
    }
   ],
   "source": [
    "envs = pong_utils.parallelEnv('PongDeterministic-v4', n=4, seed=12345)\n",
    "prob, state, action, reward = pong_utils.collect_trajectories(envs, policy, tmax=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.47036976, 0.4703716 , 0.4703699 , 0.4703689 ], dtype=float32),\n",
       " array([0.5296309 , 0.47036868, 0.47036913, 0.47036985], dtype=float32),\n",
       " array([0.52963156, 0.529632  , 0.5296289 , 0.5296316 ], dtype=float32),\n",
       " array([0.52963793, 0.52963805, 0.5296386 , 0.4703621 ], dtype=float32),\n",
       " array([0.47037345, 0.5296265 , 0.52962625, 0.47037354], dtype=float32),\n",
       " array([0.47037902, 0.5296226 , 0.47037914, 0.52962077], dtype=float32),\n",
       " array([0.470371  , 0.5296273 , 0.47037244, 0.47037256], dtype=float32),\n",
       " array([0.4703762, 0.4703728, 0.5296278, 0.5296271], dtype=float32),\n",
       " array([0.52963203, 0.5296303 , 0.47036985, 0.5296302 ], dtype=float32),\n",
       " array([0.52963173, 0.47036976, 0.5296309 , 0.47036982], dtype=float32),\n",
       " array([0.47036853, 0.47036916, 0.52963066, 0.5296315 ], dtype=float32),\n",
       " array([0.4703749 , 0.47037148, 0.47037217, 0.47037223], dtype=float32),\n",
       " array([0.47037065, 0.47037524, 0.47037238, 0.4703717 ], dtype=float32),\n",
       " array([0.47037244, 0.5296286 , 0.52962816, 0.4703726 ], dtype=float32),\n",
       " array([0.5296315 , 0.52963173, 0.47036907, 0.470369  ], dtype=float32),\n",
       " array([0.52963036, 0.47036827, 0.47036934, 0.5296299 ], dtype=float32),\n",
       " array([0.4703738 , 0.47037593, 0.47037694, 0.52962583], dtype=float32),\n",
       " array([0.5296278 , 0.5296286 , 0.47037143, 0.4703725 ], dtype=float32),\n",
       " array([0.5296341 , 0.52963376, 0.4703667 , 0.52963376], dtype=float32),\n",
       " array([0.5296328 , 0.47036648, 0.5296316 , 0.52963173], dtype=float32),\n",
       " array([0.5296351 , 0.47036743, 0.5296347 , 0.52963454], dtype=float32),\n",
       " array([0.47037345, 0.5296276 , 0.52962744, 0.47037324], dtype=float32),\n",
       " array([0.47037303, 0.52962637, 0.5296256 , 0.4703745 ], dtype=float32),\n",
       " array([0.529629  , 0.47036612, 0.5296339 , 0.4703684 ], dtype=float32),\n",
       " array([0.47036922, 0.52962863, 0.52963006, 0.5296313 ], dtype=float32),\n",
       " array([0.4703689 , 0.47036797, 0.47036406, 0.5296359 ], dtype=float32),\n",
       " array([0.52963114, 0.47037956, 0.47037354, 0.5296265 ], dtype=float32),\n",
       " array([0.52962744, 0.52962875, 0.5296261 , 0.4703744 ], dtype=float32),\n",
       " array([0.47037175, 0.52962554, 0.47037143, 0.47037143], dtype=float32),\n",
       " array([0.5296236 , 0.52962834, 0.47036675, 0.52963203], dtype=float32),\n",
       " array([0.52962506, 0.5296286 , 0.47037375, 0.5296291 ], dtype=float32),\n",
       " array([0.47037354, 0.4703657 , 0.4703705 , 0.47037134], dtype=float32),\n",
       " array([0.4703631 , 0.5296304 , 0.4703688 , 0.47036913], dtype=float32),\n",
       " array([0.47037813, 0.5296304 , 0.52962863, 0.52962834], dtype=float32),\n",
       " array([0.5296228 , 0.47036546, 0.5296336 , 0.4703667 ], dtype=float32),\n",
       " array([0.47036627, 0.47037408, 0.4703686 , 0.47036982], dtype=float32),\n",
       " array([0.47036585, 0.470369  , 0.52962446, 0.47037396], dtype=float32),\n",
       " array([0.5296296 , 0.5296254 , 0.4703755 , 0.47037566], dtype=float32),\n",
       " array([0.52963865, 0.52963406, 0.52963114, 0.4703684 ], dtype=float32),\n",
       " array([0.52962923, 0.47036675, 0.47037834, 0.5296215 ], dtype=float32),\n",
       " array([0.5296279 , 0.52963555, 0.5296316 , 0.52963215], dtype=float32),\n",
       " array([0.5296328 , 0.52962804, 0.52963173, 0.52963156], dtype=float32),\n",
       " array([0.47037113, 0.5296329 , 0.52963006, 0.5296302 ], dtype=float32),\n",
       " array([0.5296347 , 0.5296327 , 0.529632  , 0.47036964], dtype=float32),\n",
       " array([0.52963126, 0.47036996, 0.52962995, 0.4703699 ], dtype=float32),\n",
       " array([0.4703716 , 0.47036964, 0.47036955, 0.52962995], dtype=float32),\n",
       " array([0.52962506, 0.47036827, 0.4703706 , 0.5296294 ], dtype=float32),\n",
       " array([0.52962977, 0.52962697, 0.5296298 , 0.5296293 ], dtype=float32),\n",
       " array([0.5296331 , 0.47036928, 0.5296289 , 0.47037092], dtype=float32),\n",
       " array([0.52962947, 0.5296279 , 0.47037092, 0.5296296 ], dtype=float32),\n",
       " array([0.4703664 , 0.4703744 , 0.52963257, 0.4703673 ], dtype=float32),\n",
       " array([0.52963084, 0.4703783 , 0.52962995, 0.5296304 ], dtype=float32),\n",
       " array([0.529631  , 0.52963346, 0.5296246 , 0.52962476], dtype=float32),\n",
       " array([0.47036886, 0.47037697, 0.52963066, 0.52963054], dtype=float32),\n",
       " array([0.47037038, 0.5296341 , 0.5296241 , 0.47037518], dtype=float32),\n",
       " array([0.4703678 , 0.4703669 , 0.52962554, 0.4703744 ], dtype=float32),\n",
       " array([0.5296341 , 0.47036797, 0.5296254 , 0.4703727 ], dtype=float32),\n",
       " array([0.5296309 , 0.52963024, 0.47037512, 0.52962583], dtype=float32),\n",
       " array([0.4703689 , 0.5296314 , 0.5296351 , 0.47036484], dtype=float32),\n",
       " array([0.47036907, 0.5296314 , 0.52963006, 0.52963054], dtype=float32),\n",
       " array([0.52962744, 0.47036996, 0.52963066, 0.47036922], dtype=float32),\n",
       " array([0.52963126, 0.5296265 , 0.52963024, 0.5296308 ], dtype=float32),\n",
       " array([0.5296302 , 0.4703705 , 0.47036976, 0.47036964], dtype=float32),\n",
       " array([0.47036976, 0.47037354, 0.5296314 , 0.52963185], dtype=float32),\n",
       " array([0.47036976, 0.4703657 , 0.52962923, 0.5296293 ], dtype=float32),\n",
       " array([0.47036827, 0.52962995, 0.4703746 , 0.4703747 ], dtype=float32),\n",
       " array([0.5296353 , 0.5296257 , 0.5296288 , 0.47037005], dtype=float32),\n",
       " array([0.47037086, 0.5296316 , 0.5296327 , 0.4703664 ], dtype=float32),\n",
       " array([0.52962077, 0.5296247 , 0.5296291 , 0.47037098], dtype=float32),\n",
       " array([0.52962863, 0.4703746 , 0.5296286 , 0.52962804], dtype=float32),\n",
       " array([0.47036943, 0.52962667, 0.52963054, 0.52963054], dtype=float32),\n",
       " array([0.47037017, 0.5296247 , 0.52962506, 0.4703747 ], dtype=float32),\n",
       " array([0.4703727 , 0.47036502, 0.47037557, 0.5296242 ], dtype=float32),\n",
       " array([0.52963233, 0.52962995, 0.52963185, 0.47036797], dtype=float32),\n",
       " array([0.52963173, 0.52963233, 0.4703784 , 0.4703786 ], dtype=float32),\n",
       " array([0.47036913, 0.4703664 , 0.47036776, 0.52963173], dtype=float32),\n",
       " array([0.47037238, 0.5296322 , 0.5296327 , 0.4703684 ], dtype=float32),\n",
       " array([0.4703682 , 0.52963173, 0.52963006, 0.47037023], dtype=float32),\n",
       " array([0.5296299 , 0.5296304 , 0.52963024, 0.47036886], dtype=float32),\n",
       " array([0.5296297 , 0.47037488, 0.5296302 , 0.47036985], dtype=float32),\n",
       " array([0.47037005, 0.470367  , 0.47037113, 0.47036964], dtype=float32),\n",
       " array([0.5296354 , 0.52963686, 0.52963066, 0.5296293 ], dtype=float32),\n",
       " array([0.4703688 , 0.52963376, 0.4703744 , 0.47037092], dtype=float32),\n",
       " array([0.4703686 , 0.47037122, 0.52962816, 0.52962893], dtype=float32),\n",
       " array([0.52962846, 0.47037122, 0.47037208, 0.47037098], dtype=float32),\n",
       " array([0.47037366, 0.4703666 , 0.5296266 , 0.47036752], dtype=float32),\n",
       " array([0.52962863, 0.5296288 , 0.4703782 , 0.5296298 ], dtype=float32),\n",
       " array([0.5296314 , 0.52962846, 0.47036368, 0.52962446], dtype=float32),\n",
       " array([0.5296316 , 0.47036922, 0.52963364, 0.47036943], dtype=float32),\n",
       " array([0.4703668 , 0.4703666 , 0.5296297 , 0.52962476], dtype=float32),\n",
       " array([0.5296276 , 0.52962506, 0.5296354 , 0.5296254 ], dtype=float32),\n",
       " array([0.52963066, 0.5296375 , 0.47036847, 0.52962554], dtype=float32),\n",
       " array([0.5296302 , 0.47036955, 0.47037533, 0.47037497], dtype=float32),\n",
       " array([0.52963024, 0.47036928, 0.5296257 , 0.4703651 ], dtype=float32),\n",
       " array([0.47036913, 0.52962697, 0.4703705 , 0.4703705 ], dtype=float32),\n",
       " array([0.47037122, 0.5296307 , 0.5296304 , 0.47036847], dtype=float32),\n",
       " array([0.52962816, 0.47036985, 0.5296283 , 0.5296302 ], dtype=float32),\n",
       " array([0.52963006, 0.5296315 , 0.4703716 , 0.5296302 ], dtype=float32),\n",
       " array([0.5296313 , 0.47036943, 0.52962655, 0.5296313 ], dtype=float32),\n",
       " array([0.5296333 , 0.52962637, 0.52962303, 0.52962923], dtype=float32)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Definitions\n",
    "Here you will define key functions for training. \n",
    "\n",
    "## Exercise 2: write your own function for training\n",
    "(this is the same as policy_loss except the negative sign)\n",
    "\n",
    "### REINFORCE\n",
    "you have two choices (usually it's useful to divide by the time since we've normalized our rewards and the time of each trajectory is fixed)\n",
    "\n",
    "1. $\\frac{1}{T}\\sum^T_t R_{t}^{\\rm future}\\log(\\pi_{\\theta'}(a_t|s_t))$\n",
    "2. $\\frac{1}{T}\\sum^T_t R_{t}^{\\rm future}\\frac{\\pi_{\\theta'}(a_t|s_t)}{\\pi_{\\theta}(a_t|s_t)}$ where $\\theta'=\\theta$ and make sure that the no_grad is enabled when performing the division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discounted_future_rewards(rewards, ratio=0.999):\n",
    "    \n",
    "    n = rewards.shape[1]\n",
    "    step = torch.arange(n)[:,None] - torch.arange(n)[None,:]\n",
    "    ones = torch.ones_like(step)\n",
    "    zeros = torch.zeros_like(step)\n",
    "    \n",
    "    target = torch.where(step >= 0, ones, zeros)\n",
    "    step = torch.where(step >= 0, step, zeros)    \n",
    "    discount = target * (ratio ** step)\n",
    "    discount = discount.to(device)\n",
    "    \n",
    "    rewards_discounted = torch.mm(rewards, discount.float())\n",
    "    return rewards_discounted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def surrogate(policy, old_probs, states, actions, rewards,\n",
    "              discount = 0.995, beta=0.01):\n",
    "\n",
    "    actions = torch.tensor(actions, dtype=torch.int8, device=device)\n",
    "    rewards = torch.tensor(rewards, dtype=torch.float, device=device)\n",
    "    old_probs = torch.tensor(old_probs, dtype=torch.float, device=device)\n",
    "    \n",
    "    # convert states to policy (or probability)\n",
    "    new_probs = pong_utils.states_to_prob(policy, states)\n",
    "    new_probs = torch.where(actions == pong_utils.RIGHT, new_probs, 1.0-new_probs)\n",
    "\n",
    "    # discounted cumulative reward\n",
    "    R_future = discounted_future_rewards(rewards, discount)\n",
    "\n",
    "    # subtract baseline (= mean of reward)\n",
    "    R_mean = torch.mean(R_future)\n",
    "    R_future -= R_mean\n",
    "\n",
    "    # policy gradient maxmize target\n",
    "    surrogates = (R_future * torch.log(new_probs)).mean()\n",
    "    \n",
    "    # include a regularization term\n",
    "    # this steers new_policy towards 0.5\n",
    "    # which prevents policy to become exactly 0 or 1\n",
    "    # this helps with exploration\n",
    "    # add in 1.e-10 to avoid log(0) which gives nan\n",
    "    # entropy = -(new_probs*torch.log(old_probs+1.e-10) + (1.0-new_probs)*torch.log(1.0-old_probs+1.e-10))\n",
    "    # surrogates += torch.mean(beta*entropy)\n",
    "\n",
    "    return surrogates\n",
    "\n",
    "\n",
    "Lsur= surrogate(policy, prob, state, action, reward)\n",
    "\n",
    "print(Lsur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "We are now ready to train our policy!\n",
    "WARNING: make sure to turn on GPU, which also enables multicore processing. It may take up to 45 minutes even with GPU enabled, otherwise it will take much longer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   2% |                                           | ETA:  1:41:28\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 20, score: -3.750000\n",
      "[-4. -4. -3. -5. -1. -5. -4. -4.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   4% |#                                          | ETA:  1:25:22\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 40, score: -3.375000\n",
      "[-1. -2. -4. -3. -5. -3. -5. -4.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   6% |##                                         | ETA:  1:12:04\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 60, score: -3.750000\n",
      "[-3. -4. -3. -3. -4. -5. -4. -4.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:   8% |###                                        | ETA:  1:06:05\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 80, score: -4.000000\n",
      "[-4. -5. -5. -2. -3. -4. -5. -4.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  10% |####                                       | ETA:  1:01:53\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 100, score: -3.875000\n",
      "[-4. -4. -3. -4. -4. -4. -3. -5.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  12% |#####                                      | ETA:  0:58:07\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 120, score: -4.125000\n",
      "[-4. -5. -5. -3. -4. -5. -3. -4.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  14% |######                                     | ETA:  0:54:28\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 140, score: -4.000000\n",
      "[-4. -4. -4. -4. -4. -3. -4. -5.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  16% |######                                     | ETA:  0:51:51\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 160, score: -3.500000\n",
      "[-4. -4. -5. -1. -3. -4. -3. -4.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  18% |#######                                    | ETA:  0:49:16\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 180, score: -3.000000\n",
      "[-4. -2. -3. -2. -3. -3. -3. -4.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  20% |########                                   | ETA:  0:47:00\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 200, score: -3.500000\n",
      "[-4. -3. -4. -4. -4. -4. -3. -2.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  22% |#########                                  | ETA:  0:45:23\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 220, score: -3.875000\n",
      "[-4. -4. -4. -4. -5. -3. -2. -5.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  24% |##########                                 | ETA:  0:43:50\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 240, score: -3.500000\n",
      "[-3. -3. -4. -3. -5. -5. -3. -2.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  26% |###########                                | ETA:  0:42:20\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 260, score: -3.625000\n",
      "[-5. -4. -3. -4. -4. -3. -3. -3.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  28% |############                               | ETA:  0:40:56\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 280, score: -2.375000\n",
      "[-4.  2. -3. -1. -3. -3. -4. -3.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  30% |############                               | ETA:  0:39:37\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 300, score: -3.875000\n",
      "[-4. -5. -3. -3. -4. -5. -3. -4.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  32% |#############                              | ETA:  0:38:19\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 320, score: -3.125000\n",
      "[-3. -3. -5. -3. -3. -1. -4. -3.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  34% |##############                             | ETA:  0:37:02\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 340, score: -3.250000\n",
      "[-4. -3. -2. -4. -2. -3. -4. -4.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  36% |###############                            | ETA:  0:35:48\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 360, score: -3.500000\n",
      "[-5. -3. -4. -5. -4. -2. -2. -3.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  38% |################                           | ETA:  0:34:34\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 380, score: -3.750000\n",
      "[-4. -4. -3. -4. -3. -4. -4. -4.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  40% |#################                          | ETA:  0:33:22\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 400, score: -3.500000\n",
      "[-4. -2. -4. -3. -3. -4. -4. -4.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  42% |##################                         | ETA:  0:32:11\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 420, score: -3.375000\n",
      "[-3. -3. -4. -4. -2. -2. -5. -4.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  44% |##################                         | ETA:  0:31:00\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 440, score: -2.875000\n",
      "[-4. -4. -3. -4. -2. -3.  0. -3.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  46% |###################                        | ETA:  0:29:50\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 460, score: -3.500000\n",
      "[-4. -4. -3. -2. -5. -3. -4. -3.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  48% |####################                       | ETA:  0:28:41\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 480, score: -3.500000\n",
      "[-5. -4.  0. -5. -3. -4. -3. -4.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  50% |#####################                      | ETA:  0:27:25\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 500, score: -3.125000\n",
      "[-4. -3. -3. -2. -5. -3. -2. -3.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  52% |######################                     | ETA:  0:26:11\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 520, score: -3.000000\n",
      "[-3. -3. -1. -4. -3. -3. -3. -4.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  54% |#######################                    | ETA:  0:24:57\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 540, score: -4.375000\n",
      "[-5. -4. -4. -5. -4. -4. -5. -4.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  56% |########################                   | ETA:  0:23:46\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 560, score: -4.250000\n",
      "[-4. -4. -4. -5. -4. -4. -5. -4.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  58% |########################                   | ETA:  0:22:35\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 580, score: -3.625000\n",
      "[-3. -4. -4. -4. -3. -4. -4. -3.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  60% |#########################                  | ETA:  0:21:25\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 600, score: -3.000000\n",
      "[-4. -4. -1. -2. -5. -3. -1. -4.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  62% |##########################                 | ETA:  0:20:16\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 620, score: -3.625000\n",
      "[-4. -3. -4. -3. -2. -5. -5. -3.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  64% |###########################                | ETA:  0:19:08\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 640, score: -3.500000\n",
      "[-4. -2. -3. -4. -4. -3. -3. -5.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  66% |############################               | ETA:  0:18:00\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 660, score: -4.000000\n",
      "[-4. -4. -3. -4. -5. -4. -4. -4.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  68% |#############################              | ETA:  0:16:53\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 680, score: -3.625000\n",
      "[-4. -3. -4. -4. -4. -4. -1. -5.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  70% |##############################             | ETA:  0:15:47\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 700, score: -3.625000\n",
      "[-4. -3. -4. -5. -3. -3. -4. -3.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  72% |##############################             | ETA:  0:14:41\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 720, score: -3.500000\n",
      "[-3. -4. -3. -3. -4. -4. -4. -3.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  74% |###############################            | ETA:  0:13:36\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 740, score: -3.375000\n",
      "[-4. -3. -3. -5. -4. -1. -3. -4.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  76% |################################           | ETA:  0:12:31\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 760, score: -3.625000\n",
      "[-3. -5. -4. -4. -5. -4. -3. -1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  78% |#################################          | ETA:  0:11:27\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 780, score: -3.375000\n",
      "[-4. -3. -3. -3. -4. -4. -3. -3.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  80% |##################################         | ETA:  0:10:23\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 800, score: -3.500000\n",
      "[-4. -5. -4. -5. -3. -4. -3.  0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  82% |###################################        | ETA:  0:09:19\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 820, score: -3.125000\n",
      "[-4. -2. -2. -3. -4. -4. -3. -3.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  84% |####################################       | ETA:  0:08:16\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 840, score: -3.375000\n",
      "[-5. -4. -5. -1. -3. -3. -4. -2.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  86% |####################################       | ETA:  0:07:13\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 860, score: -3.125000\n",
      "[-3. -5. -4. -3. -3. -1. -3. -3.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  88% |#####################################      | ETA:  0:06:10\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 880, score: -3.125000\n",
      "[-4. -2. -3. -4. -1. -4. -3. -4.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  90% |######################################     | ETA:  0:05:08\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 900, score: -4.000000\n",
      "[-5. -4. -5. -3. -3. -5. -3. -4.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  92% |#######################################    | ETA:  0:04:06\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 920, score: -3.250000\n",
      "[-4. -1. -5. -4. -1. -4. -4. -3.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  94% |########################################   | ETA:  0:03:04\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 940, score: -3.750000\n",
      "[-3. -3. -4. -4. -4. -5. -4. -3.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  96% |#########################################  | ETA:  0:02:02\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 960, score: -3.625000\n",
      "[-2. -5. -3. -3. -4. -5. -4. -3.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop:  98% |########################################## | ETA:  0:01:01\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 980, score: -3.750000\n",
      "[-4. -4. -3. -5. -3. -3. -5. -3.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training loop: 100% |###########################################| Time: 0:50:57\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1000, score: -2.750000\n",
      "[-3. -3. -2. -1. -4. -2. -4. -3.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from parallelEnv import parallelEnv\n",
    "import numpy as np\n",
    "# WARNING: running through all 800 episodes will take 30-45 minutes\n",
    "\n",
    "# training loop max iterations\n",
    "episode = 1000\n",
    "# episode = 800\n",
    "\n",
    "# widget bar to display progress\n",
    "import progressbar as pb\n",
    "widget = ['training loop: ', pb.Percentage(), ' ', \n",
    "          pb.Bar(), ' ', pb.ETA() ]\n",
    "timer = pb.ProgressBar(widgets=widget, maxval=episode).start()\n",
    "\n",
    "# initialize environment\n",
    "envs = parallelEnv('PongDeterministic-v4', n=8, seed=1234)\n",
    "\n",
    "discount_rate = .99\n",
    "beta = .01\n",
    "tmax = 100\n",
    "\n",
    "# keep track of progress\n",
    "mean_rewards = []\n",
    "\n",
    "for e in range(episode):\n",
    "\n",
    "    # collect trajectories\n",
    "    old_probs, states, actions, rewards = \\\n",
    "        pong_utils.collect_trajectories(envs, policy, tmax=tmax)\n",
    "        \n",
    "    total_rewards = np.sum(rewards, axis=0)\n",
    "\n",
    "    # this is the SOLUTION!\n",
    "    # use your own surrogate function\n",
    "    # L = -surrogate(policy, old_probs, states, actions, rewards, beta=beta)\n",
    "    \n",
    "    L = -pong_utils.surrogate(policy, old_probs, states, actions, rewards, beta=beta)\n",
    "    optimizer.zero_grad()\n",
    "    L.backward()\n",
    "    optimizer.step()\n",
    "    del L\n",
    "        \n",
    "    # the regulation term also reduces\n",
    "    # this reduces exploration in later runs\n",
    "    beta*=.995\n",
    "    \n",
    "    # get the average reward of the parallel environments\n",
    "    mean_rewards.append(np.mean(total_rewards))\n",
    "    \n",
    "    # display some progress every 20 iterations\n",
    "    if (e+1)%20 ==0 :\n",
    "        print(\"Episode: {0:d}, score: {1:f}\".format(e+1,np.mean(total_rewards)))\n",
    "        print(total_rewards)\n",
    "        \n",
    "    # update progress widget bar\n",
    "    timer.update(e+1)\n",
    "    \n",
    "timer.finish()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-2b1d90fde400>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# play game after training!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpong_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\reinforcment learning\\deep-reinforcement-learning\\Udacity-DeepRL-PPO-master\\pong_utils.py\u001b[0m in \u001b[0;36mplay\u001b[1;34m(env, policy, time, preprocess, nrand)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m     \u001b[0manimate_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manim_frames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\reinforcment learning\\deep-reinforcement-learning\\Udacity-DeepRL-PPO-master\\pong_utils.py\u001b[0m in \u001b[0;36manimate_frames\u001b[1;34m(frames)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;31m#print((dtype))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m     \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdisplay_animation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfanim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'once'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;31m# play a game and display the animation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\drl\\lib\\site-packages\\JSAnimation\\IPython_display.py\u001b[0m in \u001b[0;36mdisplay_animation\u001b[1;34m(anim, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;34m\"\"\"Display the animation with an IPython HTML object\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHTML\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mHTML\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manim_to_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\drl\\lib\\site-packages\\JSAnimation\\IPython_display.py\u001b[0m in \u001b[0;36manim_to_html\u001b[1;34m(anim, fps, embed_frames, default_mode)\u001b[0m\n\u001b[0;32m     74\u001b[0m             anim.save(f.name,  writer=HTMLWriter(fps=fps,\n\u001b[0;32m     75\u001b[0m                                                  \u001b[0membed_frames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0membed_frames\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m                                                  default_mode=default_mode))\n\u001b[0m\u001b[0;32m     77\u001b[0m             \u001b[0mhtml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\drl\\lib\\site-packages\\matplotlib\\animation.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filename, writer, fps, dpi, codec, bitrate, extra_args, metadata, extra_anim, savefig_kwargs, progress_callback)\u001b[0m\n\u001b[0;32m   1154\u001b[0m                             \u001b[0mprogress_callback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe_number\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_frames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1155\u001b[0m                             \u001b[0mframe_number\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1156\u001b[1;33m                     \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrab_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0msavefig_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1158\u001b[0m         \u001b[1;31m# Reconnect signal for first draw if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\drl\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\drl\\lib\\site-packages\\matplotlib\\animation.py\u001b[0m in \u001b[0;36msaving\u001b[1;34m(self, fig, outfile, dpi, *args, **kwargs)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\drl\\lib\\site-packages\\matplotlib\\animation.py\u001b[0m in \u001b[0;36mfinish\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    526\u001b[0m         \u001b[1;31m# are available to be assembled.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m         \u001b[0mMovieWriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Will call clean-up\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\drl\\lib\\site-packages\\matplotlib\\animation.py\u001b[0m in \u001b[0;36mfinish\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfinish\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[1;34m'''Finish any processing for writing the movie.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgrab_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msavefig_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\drl\\lib\\site-packages\\matplotlib\\animation.py\u001b[0m in \u001b[0;36mcleanup\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m         \u001b[0mMovieWriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[1;31m# Delete temporary files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\drl\\lib\\site-packages\\matplotlib\\animation.py\u001b[0m in \u001b[0;36mcleanup\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    397\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_frame_sink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;31m# Use the encoding/errors that universal_newlines would use.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextIOWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m         \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextIOWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "# play game after training!\n",
    "pong_utils.play(env, policy, time=2000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x28718b37f48>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mean_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your policy!\n",
    "torch.save(policy, 'REINFORCE.policy')\n",
    "\n",
    "# load your policy if needed\n",
    "# policy = torch.load('REINFORCE.policy')\n",
    "\n",
    "# try and test out the solution!\n",
    "# policy = torch.load('PPO_solution.policy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
